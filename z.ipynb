{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from Utils.tensor_board import Tensorboard\n",
    "import os\n",
    "import torch\n",
    "import numpy\n",
    "import random\n",
    "import argparse\n",
    "import datetime\n",
    "from train import Trainer\n",
    "from Utils.logger import *\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from Configs.config import config\n",
    "from Dataloader.dataset import LAHeartDataset\n",
    "from Dataloader.dataloader import TwoStreamBatchSampler\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    # update the default config with the args\n",
    "    config.update(vars(args))\n",
    "\n",
    "    def worker_init_fn(worker_id):\n",
    "        random.seed(config.seed + worker_id)\n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "\n",
    "    train_set = LAHeartDataset(\n",
    "        os.path.join(config.code_path, \"Datasets/Left_Atrium/labels\"),\n",
    "        config.data_path,\n",
    "        split=\"train\",\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # merge both labelled & unlabelled sampler to same batch\n",
    "    batch_sampler = TwoStreamBatchSampler(\n",
    "        list(range(config.labeled_num)),\n",
    "        list(range(config.labeled_num, 80)),\n",
    "        config.batch_size,\n",
    "        int(config.batch_size / 2),\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_sampler=batch_sampler,\n",
    "        num_workers=config.num_workers,\n",
    "        pin_memory=False,\n",
    "        worker_init_fn=worker_init_fn,\n",
    "    )\n",
    "\n",
    "    val_dataset = LAHeartDataset(\n",
    "        os.path.join(config.code_path, \"Datasets/Left_Atrium/labels\"),\n",
    "        config.data_path,\n",
    "        split=\"eval\",\n",
    "        num=None,\n",
    "        config=config,\n",
    "    )\n",
    "    return val_dataset\n",
    "    config.iter_per_epoch = len(train_loader)\n",
    "    config.n_epochs = config.max_iterations // len(train_loader) + 1\n",
    "    config.unlabeled_num = len(train_set) - config.labeled_num\n",
    "\n",
    "    logger = logging.getLogger(\"VNET_LA\")\n",
    "    logger.propagate = False\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "        filename=f\"scores_output/app_{current_time}.log\",\n",
    "    )\n",
    "    file_handler = logging.FileHandler(f\"scores_output/app_{current_time}.log\")\n",
    "    file_handler.setLevel(logging.INFO)  \n",
    "    file_handler.setFormatter(\n",
    "        logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    )\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    logger.info(\n",
    "        \"training with {} epochs [{} iters]\".format(\n",
    "            config.n_epochs, config.iter_per_epoch * config.n_epochs\n",
    "        )\n",
    "    )\n",
    "    logger.warning(\n",
    "        \"running time: \" + datetime.datetime.now().strftime(\" [%H:%M] %d/%m/%y\")\n",
    "    )\n",
    "    logger.warning(\n",
    "        \"supervised sample: {}, unsupervised sample: {}\".format(\n",
    "            config.labeled_num, config.unlabeled_num\n",
    "        )\n",
    "    )\n",
    "    logger.critical(\n",
    "        \"architecture: {}, backbone: {}\".format(\n",
    "            args.architecture, \"nothing\" if args.backbone is None else args.backbone\n",
    "        )\n",
    "    )\n",
    "    tensorboard = Tensorboard(config=config)\n",
    "    trainer = Trainer(\n",
    "        config,\n",
    "        train_loader=train_loader,\n",
    "        valid_set=val_dataset,\n",
    "        logger=logger,\n",
    "        my_wandb=tensorboard,\n",
    "    )\n",
    "    trainer.run()\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    class CmdLineVar:\n",
    "        pass\n",
    "\n",
    "    cmd_line_var = CmdLineVar()\n",
    "    cmd_line_var.architecture = \"vnet\"\n",
    "    cmd_line_var.backbone = None\n",
    "    cmd_line_var.unsup_weight = 0.3\n",
    "    cmd_line_var.labeled_num = 8\n",
    "    cmd_line_var.max_iterations = 9000\n",
    "\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "\n",
    "    random.seed(config.seed)\n",
    "    numpy.random.seed(config.seed)\n",
    "    torch.manual_seed(config.seed)\n",
    "    torch.cuda.manual_seed(config.seed)\n",
    "\n",
    "    train_set = main(cmd_line_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (normal_batch, cons_batch) in enumerate(train_set):\n",
    "    print(batch_idx, normal_batch, cons_batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([245])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 7, 7, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define your model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear1 = nn.Linear(64, 128)\n",
    "        self.linear2 = nn.Linear(128, 245)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of your model\n",
    "model = LinearModel().to(\"cuda\")\n",
    "\n",
    "# Define a sample input tensor\n",
    "sample_input = train_set[0][2].to(\"cuda\")  # Assuming batch size of 1\n",
    "\n",
    "# Pass the sample input through the model\n",
    "output = model(sample_input)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)\n",
    "output = torch.reshape(output, (1,1,7,7,5))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 7, 7, 5])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from Model.Vnet import *\n",
    "from torchsummary import summary\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "# Instantiate the VNet model\n",
    "net = VNet()\n",
    "\n",
    "# Define input sizes for the two inputs\n",
    "input_size1 = (2, 112, 112, 80)  # Assuming input size for the first input\n",
    "input_size2 = (64,)  # Assuming input size for the second input\n",
    "\n",
    "# Move input tensors to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = net.to(device)\n",
    "input_tensor1 = torch.randn(*input_size1).to(device)\n",
    "input_tensor2 = torch.randn(*input_size2).to(device)\n",
    "\n",
    "# Print the model summary\n",
    "summary(net, input_size=[input_tensor1.size(), input_tensor2.size()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# Instantiate the VNet model\n",
    "model = VNet()\n",
    "input_size1 = (2, 112, 112, 80)  # Assuming input size for the first input\n",
    "input_size2 = (64,)  # Assuming input size for the second input\n",
    "\n",
    "# Move input tensors to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "input_tensor1 = torch.randn(*input_size1).to(device)\n",
    "input_tensor2 = torch.randn(*input_size2).to(device)\n",
    "out = model(input_tensor1, input_tensor2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tracoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
